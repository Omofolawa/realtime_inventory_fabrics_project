{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca947c9-6bff-4116-bf71-f06e8590a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets to Generate\n",
    "# Inventory_Transactions.csv : Tracks inventory movement (inbound, outbound, adjustments) over time.\n",
    "# Supplier_Performance.csv : Monitors reliability, lead times, and defect rates of suppliers.\n",
    "# Purchase_Orders.csv : Contains data about procurement transactions (quantities, costs, suppliers).\n",
    "# IoT_Stock_Updates.csv : Real-time stock level updates from IoT sensors in warehouses.\n",
    "# Sales_History.csv : Historical sales data for demand forecasting.\n",
    "# Weather_Data.csv: Weather conditions by location for demand-impact analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a17a7f-370f-4509-a518-45e22a4f503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory_Transactions.csv generated with English notes!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "faker = Faker(\"en_GB\")\n",
    "\n",
    "# Generate data\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    data.append({\n",
    "        \"Transaction_ID\": faker.uuid4(),\n",
    "        \"Product_ID\": random.randint(1001, 1050),\n",
    "        \"Warehouse_Location\": faker.city(),\n",
    "        \"Transaction_Type\": random.choice([\"Inbound\", \"Outbound\", \"Adjustment\"]),\n",
    "        \"Quantity\": random.randint(-500, 500),\n",
    "        \"Transaction_Date\": faker.date_this_year(),\n",
    "        # Controlled notes in English\n",
    "        \"Notes\": random.choice([\n",
    "            \"Routine stock adjustment\",\n",
    "            \"Damaged goods removed\",\n",
    "            \"Shipment received\",\n",
    "            \"Outbound delivery processed\",\n",
    "            None, None  # Allow for some missing values\n",
    "        ])\n",
    "    })\n",
    "\n",
    "df_inventory = pd.DataFrame(data)\n",
    "df_inventory.to_csv(\"Inventory_Transactions.csv\", index=False)\n",
    "print(\"Inventory_Transactions.csv generated with English notes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd9410f-61d6-44df-ba3d-453b817b1e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier_Performance.csv generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "suppliers = [\"AlphaSupply\", \"BetaLogistics\", \"GammaDeliveries\", \"DeltaWarehousing\"]\n",
    "data = []\n",
    "for supplier in suppliers:\n",
    "    for month in range(1, 13):\n",
    "        data.append({\n",
    "            \"Supplier_ID\": suppliers.index(supplier) + 1,\n",
    "            \"Supplier_Name\": supplier,\n",
    "            \"Month\": month,\n",
    "            \"On_Time_Percentage\": random.uniform(85, 100),  # Slightly messy percentages\n",
    "            \"Defect_Rate_Percentage\": random.uniform(0, 5),\n",
    "            \"Average_Lead_Time_Days\": random.randint(1, 10)\n",
    "        })\n",
    "\n",
    "df_suppliers = pd.DataFrame(data)\n",
    "df_suppliers.to_csv(\"Supplier_Performance.csv\", index=False)\n",
    "print(\"Supplier_Performance.csv generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2230bee1-b7d4-457a-aa57-ce3972e5c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchase_Orders.csv generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "data = []\n",
    "for _ in range(500):\n",
    "    data.append({\n",
    "        \"PO_ID\": faker.uuid4(),\n",
    "        \"Supplier_ID\": random.randint(1, 4),\n",
    "        \"Product_ID\": random.randint(1001, 1050),\n",
    "        \"Order_Date\": faker.date_this_year(),\n",
    "        \"Delivery_Date\": faker.date_this_year(),\n",
    "        \"Order_Quantity\": random.randint(50, 1000),\n",
    "        \"Received_Quantity\": random.randint(40, 1000),  # Simulate errors in delivery quantities\n",
    "        \"Cost_Per_Unit\": round(random.uniform(5, 100), 2),\n",
    "        \"Status\": random.choice([\"Completed\", \"Pending\", \"Canceled\"])\n",
    "    })\n",
    "\n",
    "df_purchase_orders = pd.DataFrame(data)\n",
    "df_purchase_orders.to_csv(\"Purchase_Orders.csv\", index=False)\n",
    "print(\"Purchase_Orders.csv generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774bb845-ce24-487f-be39-3f7846c54e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoT_Stock_Updates.csv generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "data = []\n",
    "for _ in range(2000):\n",
    "    data.append({\n",
    "        \"Sensor_ID\": faker.uuid4(),\n",
    "        \"Warehouse_Location\": faker.city(),\n",
    "        \"Product_ID\": random.randint(1001, 1050),\n",
    "        \"Stock_Level\": random.randint(0, 5000),\n",
    "        \"Update_Timestamp\": faker.date_time_this_year(),\n",
    "    })\n",
    "\n",
    "df_iot_updates = pd.DataFrame(data)\n",
    "df_iot_updates.to_csv(\"IoT_Stock_Updates.csv\", index=False)\n",
    "print(\"IoT_Stock_Updates.csv generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19663542-bc69-4c3e-b2f4-2fad016d81b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales_History.csv generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "data = []\n",
    "for _ in range(2000):\n",
    "    data.append({\n",
    "        \"Transaction_ID\": faker.uuid4(),\n",
    "        \"Product_ID\": random.randint(1001, 1090),\n",
    "        \"Store_Location\": faker.city(),\n",
    "        \"Quantity_Sold\": random.randint(1, 50),\n",
    "        \"Sale_Date\": faker.date_this_year(),\n",
    "        \"Revenue\": round(random.uniform(10, 500), 2)\n",
    "    })\n",
    "\n",
    "df_sales = pd.DataFrame(data)\n",
    "df_sales.to_csv(\"Sales_History.csv\", index=False)\n",
    "print(\"Sales_History.csv generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca12118-53f9-4b51-9bb7-5e8bb8702816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather_Data.csv generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "data = []\n",
    "cities = [\"London\", \"Cardiff\", \"Manchester\", \"Birmingham\", \"Edinburgh\", \"Glasgow\"]\n",
    "for _ in range(365):  # 1 year of daily data\n",
    "    for city in cities:\n",
    "        data.append({\n",
    "            \"City\": city,\n",
    "            \"Date\": faker.date_this_year(),\n",
    "            \"Temperature_C\": round(random.uniform(-5, 30), 1),\n",
    "            \"Rainfall_mm\": round(random.uniform(0, 20), 1),\n",
    "            \"Wind_Speed_kph\": round(random.uniform(0, 50), 1),\n",
    "        })\n",
    "\n",
    "df_weather = pd.DataFrame(data)\n",
    "df_weather.to_csv(\"Weather_Data.csv\", index=False)\n",
    "print(\"Weather_Data.csv generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4177e-b328-4078-9620-112ce079947e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
